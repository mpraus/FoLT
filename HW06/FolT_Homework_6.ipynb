{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXTZ3sthLr87"
   },
   "source": [
    "# **FolT Homework 6**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alexander Praus, Maike Arnold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlpPiaEuSTw8"
   },
   "outputs": [],
   "source": [
    "# Execute before and only in colab, if you use jupyter ignore this cell\n",
    "!pip install --target=$nb_path nltk==3.5\n",
    "!python3 -m nltk.downloader popular\n",
    "!python3 -m nltk.downloader book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eo3mepfqL17n"
   },
   "source": [
    "### Homework 6.1 (10 points)\n",
    "Implement an SMS decoder.  Similar to the T9 system on mobile phones, your decoder should translate from digit sequences to words:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpSGy2VXyxDi"
   },
   "source": [
    "a) Choose at least one appropriate corpus and discuss,  why you chose this corpus. You will use the corpus to estimate which word is more frequent and should be a preferred output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_tNVwBc_0rP"
   },
   "source": [
    "We will be using the nps_chat corpus. This corpus contains a collection of instant messaging chat sessions[^1]. Therefore, this corpus contains much more relevant texts than, for example, the Gutenberg corpus when working with informal text sources such as SMS. A chat corpus is also more likely to take into consideration abbreviations often used in SMS.\n",
    "\n",
    "[^1]: https://www.nltk.org/book/ch02.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tGGj8oPzAA9"
   },
   "source": [
    "b) Implement a function `get_T9_word(digits)` which for a given sequence of digits, e.g. \"252473\", returns themost likely word, e.g. \"Claire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import nps_chat\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLsvPUGzzMAB"
   },
   "outputs": [],
   "source": [
    "T9_dict = {0: ' ', 1:'.?!', 2: ['a','b','c'],3: ['d','e','f'],4: ['g','h','i'],5: ['j','k','l'],6: ['m','n','o'],7: ['p','q','r','s'],8: ['t','u','v'],9: ['w','x','y','z']}\n",
    "# T9_dict = {2: ['a','b','c'],3: ['d','e','f'],4: ['g','h','i'],5: ['j','k','l'],6: ['m','n','o'],7: ['p','q','r','s'],8: ['t','u','v'],9: ['w','x','y','z']}\n",
    "\n",
    "fq = nltk.FreqDist([word.lower() for word in nps_chat.words()])\n",
    "# fq = nltk.FreqDist([word.lower() for word in brown.words()])\n",
    "\n",
    "def get_T9_word(digits):\n",
    "    words = []\n",
    "    for digit in digits:\n",
    "        if int(digit) not in T9_dict:\n",
    "            return None\n",
    "        if len(words) == 0:\n",
    "            words.extend(T9_dict[int(digit)])\n",
    "        else:\n",
    "            words = list(set([a+b for a in words for b in T9_dict[int(digit)]]))\n",
    "    prob = 0\n",
    "    word = ''\n",
    "    for pos in words:\n",
    "        if fq[pos] > prob:\n",
    "            prob = fq[pos]\n",
    "            word = pos\n",
    "    if prob != 0:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7mezYVWSaCw"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "print(get_T9_word('252473')) # claire\n",
    "print(get_T9_word('4663'), get_T9_word('3836464')) # good evening\n",
    "print(get_T9_word('9352663')) # welcome\n",
    "print(get_T9_word('4373')) # here\n",
    "print(get_T9_word('1111')) # no word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment\n",
    "\n",
    "It was not 100% clear to us what the encoding should look like. We assumed that all number 0-9 should be considered. This leads to the problem that `print(get_T9_word('1111')) # no word` is not true using out chosen corpus. However, when using for exampel the Brown corpus, we achieve a similiar result (to test this, simply toggle comments on the two lines with FreqDists). We chose to continue using the nps_chat corpus. This also affects the results in part (c). In this case the result is `hello my friend peter i an find` and the errors can be explained the same way the second error is explained in part (c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZtXyvPnzMO9"
   },
   "source": [
    "c) Apply the decoder to each digit sequence in this “sentence”: \n",
    "\n",
    "`['43556','69','374363','73837','4','26','3463']`\n",
    "\n",
    "The original sentence was: *“hello my friend peter i am fine”* \n",
    "\n",
    "Is the output readable?\n",
    "What errors have been made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jorpp4s_zavS"
   },
   "outputs": [],
   "source": [
    "digits = ['43556','69','374363','73837','4','26','3463']\n",
    "for digit in digits:\n",
    "    print(get_T9_word(digit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKi0X2qtzhY9"
   },
   "source": [
    "The output contains two mistakes.\n",
    "1. Peter: there was no word found in the corpus that corresponds to the didgets making up the name Peter. The reason for this is most likely due to that fact that pronouns are likely relatively rare in the given corpus. Therefore, it is easy for a specific name to be missing.\n",
    "2. fine: Insted of returning 'fine' the word 'find' was returned. This is simply due to the fact that the word 'find' is more common in the corpus and the fac that the method does not take context or grammatical correctness into consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sXsfq0Czhrl"
   },
   "source": [
    "### Homework 6.2\n",
    "This is a quite complicated optional task that you might explore if you are interested. It will not count as part of the official homework assignment.Improve the SMS decoder of homework 6.1 as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Prg6be0VzxRR"
   },
   "source": [
    "a) Take the context into account, guess the word using the bigram probability of the previous entered word with the function `get_T9_word(prevW ord, number)`. Test the improvement with the `(context_word, digit)` tuples inthe following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fq = nltk.FreqDist([word.lower() for word in brown.words()])\n",
    "def get_all_T9_words(digits):\n",
    "    words = []\n",
    "    for digit in digits:\n",
    "        if int(digit) not in T9_dict:\n",
    "            return None\n",
    "        if len(words) == 0:\n",
    "            words.extend(T9_dict[int(digit)])\n",
    "        else:\n",
    "            words = list(set([a+b for a in words for b in T9_dict[int(digit)]]))\n",
    "    possible = []\n",
    "    for pos in words:\n",
    "        if fq[pos]:\n",
    "            possible.append(pos)\n",
    "    return possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7KWUynk0fxn"
   },
   "outputs": [],
   "source": [
    "fq_bigrams = nltk.FreqDist([bigram for bigram in nltk.bigrams([word.lower() for word in brown.words()])])\n",
    "\n",
    "def get_T9_word(prevWord, number):\n",
    "    words = get_all_T9_words(number)\n",
    "    prob = 0\n",
    "    bigram = ''\n",
    "    for word in words:\n",
    "        if fq_bigrams[(prevWord, word)] > prob:\n",
    "            prob = fq_bigrams[(prevWord, word)]\n",
    "            bigram = word\n",
    "    if prob != 0:\n",
    "        return bigram\n",
    "    else:\n",
    "        for pos in words:\n",
    "            if fq[pos] > prob:\n",
    "                prob = fq[pos]\n",
    "                bigram = pos\n",
    "        return bigram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pj-AkagRz-k8"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "print(get_T9_word('i',    '26'))\n",
    "print(get_T9_word('its',  '26'))\n",
    "print(get_T9_word('a',    '3463'))\n",
    "print(get_T9_word('will', '3463'))\n",
    "print(get_T9_word('the',  '1111'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to switch to the Brown corpus here because the chat corpus was not leading to very useful results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcFgobGfz-wr"
   },
   "source": [
    "(b)  Apply the decoder to each digit sequence in this “sentence”:\n",
    "\n",
    "`['43556','69','374363','73837','4','26','3463']`\n",
    "\n",
    "The original sentence was: *“hello my friend peter i am fine”* \n",
    "\n",
    "Is the output readable? What errors have been made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxOjyFKj0kJa"
   },
   "outputs": [],
   "source": [
    "digits = ['43556','69','374363','73837','4','26','3463']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05zGvqpjz-_1"
   },
   "outputs": [],
   "source": [
    "sentence = ['']\n",
    "for digit in digits:\n",
    "    sentence.append(get_T9_word(sentence[len(sentence)-1], digit))\n",
    "sentence = sentence [1:]\n",
    "print(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32AY3Jcr_ZUz"
   },
   "source": [
    "This lead to a slight improvement. We now get 'am' instead of 'an' but the we still recieve 'find' instead of 'fine'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "FolT_Homework_6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
