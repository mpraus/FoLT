{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework4Updated.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QclFG5At3yv9"
      },
      "source": [
        "# Run this cell once before doing anything else\n",
        "!pip install --target=$nb_path nltk==3.5\n",
        "!python3 -m nltk.downloader udhr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZjpTzGSGIGq"
      },
      "source": [
        "import nltk \n",
        "from nltk.corpus import udhr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eJbvgQfHXvb"
      },
      "source": [
        "##Homework 4.1 (6 points)\n",
        "\n",
        "Implement a language guesser, i.e. a function that takes a given text and outputs the language it thinks the text is\n",
        "written in. The function should base its decision on the frequency of individual characters in each language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucDND7klGVMg"
      },
      "source": [
        "# build the language models\n",
        "# udhr contains the Universal Declaration of Human Rights in over 300 languages\n",
        "languages = ['English', 'German_Deutsch', 'Spanish']\n",
        "language_base = dict((language, udhr.words(language + '-Latin1')) for language in languages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzUAUu8d6xr0"
      },
      "source": [
        "a) Implement a function `build_language_models(languages,words)` which takes a list of languages and a\n",
        "dictionary of words as arguments and returns a conditional frequency distribution where:\n",
        "*   the languages are the conditions\n",
        "*   the values are the lower case characters found in `words[language]`\n",
        "\n",
        "Call the function as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0LXcNdp4AWJ"
      },
      "source": [
        "def build_language_models(languages, words):\n",
        "  print('not implemented')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n4FJ9nMJGCP"
      },
      "source": [
        "language_model_cfd = build_language_models(languages, language_base)\n",
        "\n",
        "# print the models for visual inspection (you always should have a look at the data :)\n",
        "for language in languages:\n",
        "  for key in list(language_model_cfd[language].keys())[:10]:\n",
        "    print(language, key, \"->\", language_model_cfd[language].freq(key))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rCCWTozF-E_"
      },
      "source": [
        "b) Develop an algorithm which calculates the overall score of a given text based on the frequency of characters\n",
        "accessible by `language_model_cfd[language].freq(character)`. Explain how the algorithm works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tONTEw5nF-Sz"
      },
      "source": [
        "# add code here, that will be used in the next function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpscJYRTt_x0"
      },
      "source": [
        "Explain how the algorithm works here "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVCvz3mnGhwC"
      },
      "source": [
        "c) Implement a function `guess_language(language_model_cfd,text) `that returns the most likely language\n",
        "for a given text according to your algorithm from the previous sub task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crSfb-deGh-l"
      },
      "source": [
        "def guess_language(language_model_cfd, text):\n",
        "  print('not implemented')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02-goJWNGrWC"
      },
      "source": [
        "d) Test your implementation with the following data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHNGzdWGGri8"
      },
      "source": [
        "text1 = \"Peter had been to the office before they arrived.\"\n",
        "text2 = \"Si terminas tu tarea, te dare un caramelo.\"\n",
        "text3 = \"Das ist ein schon recht langes deutsches Beispiel.\"\n",
        "\n",
        "# guess the language by comparing the frequency distributions\n",
        "print('guess for english text is', guess_language(language_model_cfd, text1))\n",
        "print('guess for spanish text is', guess_language(language_model_cfd, text2))\n",
        "print('guess for german text is', guess_language(language_model_cfd, text3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFWdJBrf7IcW"
      },
      "source": [
        "e) Discuss, why English and German texts are difficult to distinguish with the given approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEzjSq_THwGc"
      },
      "source": [
        "*Answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwawqiMx77Yl"
      },
      "source": [
        "##Homework 4.2 (4 points)\n",
        "\n",
        "The previous language guesser was based on the frequency of characters. Implement alternative language guesser\n",
        "based on the following lexical units:\n",
        "\n",
        "a) tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrLvV_Ra74Tp"
      },
      "source": [
        "def build_language_models(languages, words):\n",
        "  print('not implemented')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGizC_FxJg1m"
      },
      "source": [
        "language_model_cfd = build_language_models(languages, language_base)\n",
        "\n",
        "# print the models for visual inspection (you always should have a look at the data :)\n",
        "for language in languages:\n",
        "  for key in list(language_model_cfd[language].keys())[:10]:\n",
        "    print(language, key, \"->\", language_model_cfd[language].freq(key))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM6crcvzJXVF"
      },
      "source": [
        "def guess_language(language_model_cfd, text):\n",
        "  print('not implemented')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNBB9OuLJY_1"
      },
      "source": [
        "# guess the language by comparing the frequency distributions\n",
        "print('guess for english text is', guess_language(language_model_cfd, text1))\n",
        "print('guess for spanish text is', guess_language(language_model_cfd, text2))\n",
        "print('guess for german text is', guess_language(language_model_cfd, text3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WdD9nLk8IIy"
      },
      "source": [
        "b) character bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqVsZQLtJrkO"
      },
      "source": [
        "def build_language_models(languages, words):\n",
        "  print('not implemented')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3DH5uK4JrkO"
      },
      "source": [
        "language_model_cfd = build_language_models(languages, language_base)\n",
        "\n",
        "# print the models for visual inspection (you always should have a look at the data :)\n",
        "for language in languages:\n",
        "  for key in list(language_model_cfd[language].keys())[:10]:\n",
        "    print(language, key, \"->\", language_model_cfd[language].freq(key))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWWnUeDMJrkO"
      },
      "source": [
        "def guess_language(language_model_cfd, text):\n",
        "  print('not implemented')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz-Bk5fzJrkO"
      },
      "source": [
        "# guess the language by comparing the frequency distributions\n",
        "print('guess for english text is', guess_language(language_model_cfd, text1))\n",
        "print('guess for spanish text is', guess_language(language_model_cfd, text2))\n",
        "print('guess for german text is', guess_language(language_model_cfd, text3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFo8i_SG8PGV"
      },
      "source": [
        "c) token bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpPnGvxEJ_Tt"
      },
      "source": [
        "def build_language_models(languages, words):\n",
        "  print('not implemented')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO8R67ApJ_Tt"
      },
      "source": [
        "language_model_cfd = build_language_models(languages, language_base)\n",
        "\n",
        "# print the models for visual inspection (you always should have a look at the data :)\n",
        "for language in languages:\n",
        "  for key in list(language_model_cfd[language].keys())[:10]:\n",
        "    print(language, key, \"->\", language_model_cfd[language].freq(key))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTDVkP68J_Tt"
      },
      "source": [
        "def guess_language(language_model_cfd, text):\n",
        "  print('not implemented')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mF28SghJ_Tt"
      },
      "source": [
        "# guess the language by comparing the frequency distributions\n",
        "print('guess for english text is', guess_language(language_model_cfd, text1))\n",
        "print('guess for spanish text is', guess_language(language_model_cfd, text2))\n",
        "print('guess for german text is', guess_language(language_model_cfd, text3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfDmJsx08g7N"
      },
      "source": [
        "d) Discuss, which approach should work best theoretically. Is this reflected in the results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHhi6mysKG1Q"
      },
      "source": [
        " *Answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogZK3GpCKLKy"
      },
      "source": [
        "##Homework 4.3 \n",
        "*(This homework is not part of the bonus system. However, we recommend you to work it out. It will save you some time in the future.)*\n",
        "\n",
        "Copy all functions implemented in the tasks and homeworks to one file and name it `UKP_Lib.py`. You may easily access for examle the function `word_freq` of the previous tasks with the following statement:\n",
        "\n",
        "`from UKP_Lib import word_freq`\n",
        "\n",
        "You just implemented your first module. If you are familiar with another object oriented language, feel free to use classes and OO in the exercises. Make yourself familiar with syntax of OO-constructs in Python, e.g. consult http://docs.python.org/tutorial/classes.html"
      ]
    }
  ]
}