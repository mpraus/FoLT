{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FolT_Homework_8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXTZ3sthLr87"
      },
      "source": [
        "# **FolT Homework 8**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlpPiaEuSTw8"
      },
      "source": [
        "# Execute before and only in colab, if you use jupyter ignore this cell\n",
        "!pip install --target=$nb_path nltk==3.5\n",
        "!python3 -m nltk.downloader popular\n",
        "!python3 -m nltk.downloader book\n",
        "!python3 -m nltk.downloader words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo3mepfqL17n"
      },
      "source": [
        "### Homework 8.1 (10 points)\n",
        "In natural language processing, machine learning algorithms are widely used to automatically classify texts according\n",
        "to a given task. Usually, a training and a development corpus are given in advance to prepare the classification system.\n",
        "The training corpus is used to train a system, the development corpus is used to fine-tune the parameters. The testing\n",
        "corpus is usually kept secret and is used only for the **final** evaluation of the systems. It must not be used for testing\n",
        "during the development phase and for fine-tuning.\n",
        "\n",
        "In the next task, you will create a part-of-speech tagger. The training, the development and the test set are given to you\n",
        "in advance. Your tagger is supposed to be only trained on the training corpus and maybe on the development corpus.\n",
        "You must not use the test corpus for training or fine-tuning your (hyper)parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DSz2-BIkYjS"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.corpus import nps_chat, brown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH_KXaoljCjJ"
      },
      "source": [
        "def get_train_dev_test(tagged_parts):\r\n",
        "  nr_parts = len(tagged_parts)\r\n",
        "  #first 80% of the corpus\r\n",
        "  train_parts = tagged_parts[:(nr_parts*8)//10] \r\n",
        "  # 80-90% of the corpus\r\n",
        "  development_parts = tagged_parts[(nr_parts*8)//10:(nr_parts*9)//10] \r\n",
        "  # last 10% of the corpus\r\n",
        "  test_parts = tagged_parts[((nr_parts*9)//10):] \r\n",
        "  print(nr_parts, \":\", len(train_parts), len(development_parts), len(test_parts))\r\n",
        "  return train_parts, development_parts, test_parts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I16J98SfkcD9"
      },
      "source": [
        "train_posts, development_posts, test_posts = get_train_dev_test(\r\n",
        "    nps_chat.tagged_posts(tagset='universal'))\r\n",
        "\r\n",
        "train_sents, development_sents, test_sents = get_train_dev_test(\r\n",
        "    brown.tagged_sents(tagset='universal'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpSGy2VXyxDi"
      },
      "source": [
        "**Homework 8.1** (2 points, no programming needed)\r\n",
        "\r\n",
        "Please explain why POS taggers are important for natural language processing and what kinds of downstream tasks\r\n",
        "are enabled with POS tagging (give one example). What different strategies for implementing a POS tagger do you\r\n",
        "already know and what are the pros and cons of these approaches (name at least two). Do you have suggestions how\r\n",
        "they can be improved?\r\n",
        "\r\n",
        "Answer each question in two or three sentences.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_tNVwBc_0rP"
      },
      "source": [
        "Add answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tGGj8oPzAA9"
      },
      "source": [
        "**Homework 8.2** (8 points) \r\n",
        "\r\n",
        "Develop a part-of-speech tagger for texts in the chat domain and the brown corpus. You may explore several\r\n",
        "directions such as handling rare tokens, handling special chat related phenomena like smilies, or using better and\r\n",
        "more training data. You can try different things to improve the performance of the tagger on the training data, but be\r\n",
        "careful not to overfit on the training data. Document your ideas and process well. \r\n",
        "\r\n",
        "Hints:\r\n",
        "\r\n",
        "- You do not need to implement a tagger from scratch.\r\n",
        "- You may train your tagger on more than one corpus.\r\n",
        "- The corpora provided by NLTK offer a README in the corresponding folder, i.e. within the sub folders of ``nltk\r\n",
        "\\_data/corpora`` in your home folder (``Anwendungsdaten`` for Windows) you will find additional information.\r\n",
        "- Use the universal tag set.\r\n",
        "- Typical chat tokens like *’lol’* or *’:-)’* should be tagged as *’X’*, i.e. other.\r\n",
        "- Read the paragraph *“Tagging Unknown Words”*. (See NLTK-book page chapter 5.5, page 206)\r\n",
        "- use `import matplotlib.pyplot as plt` for the plotting\r\n",
        "\r\n",
        "\r\n",
        "Collect your top 3 results on the development set for the brown and the chat corpus with the diffrerent hyperparameters and plot them. \r\n",
        "Evaluate your best tagger for brown and the chat corpus on the testset. Upload the code and report the accuracy as part of your submission. Use the\r\n",
        "text field in the submission module to submit the final accuracy (just put a single number there for each corpus).\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi1b5qOVZG4d"
      },
      "source": [
        "# add code"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}