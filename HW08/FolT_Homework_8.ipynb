{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXTZ3sthLr87"
   },
   "source": [
    "# **FolT Homework 8**\n",
    "\n",
    "## Alexander Praus, Maike Arnold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eo3mepfqL17n"
   },
   "source": [
    "### Homework 8.1 (10 points)\n",
    "In natural language processing, machine learning algorithms are widely used to automatically classify texts according\n",
    "to a given task. Usually, a training and a development corpus are given in advance to prepare the classification system.\n",
    "The training corpus is used to train a system, the development corpus is used to fine-tune the parameters. The testing\n",
    "corpus is usually kept secret and is used only for the **final** evaluation of the systems. It must not be used for testing\n",
    "during the development phase and for fine-tuning.\n",
    "\n",
    "In the next task, you will create a part-of-speech tagger. The training, the development and the test set are given to you\n",
    "in advance. Your tagger is supposed to be only trained on the training corpus and maybe on the development corpus.\n",
    "You must not use the test corpus for training or fine-tuning your (hyper)parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8DSz2-BIkYjS"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import nps_chat, brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IH_KXaoljCjJ"
   },
   "outputs": [],
   "source": [
    "def get_train_dev_test(tagged_parts):\n",
    "  nr_parts = len(tagged_parts)\n",
    "  #first 80% of the corpus\n",
    "  train_parts = tagged_parts[:(nr_parts*8)//10] \n",
    "  # 80-90% of the corpus\n",
    "  development_parts = tagged_parts[(nr_parts*8)//10:(nr_parts*9)//10] \n",
    "  # last 10% of the corpus\n",
    "  test_parts = tagged_parts[((nr_parts*9)//10):] \n",
    "  print(nr_parts, \":\", len(train_parts), len(development_parts), len(test_parts))\n",
    "  return train_parts, development_parts, test_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "I16J98SfkcD9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10567 : 8453 1057 1057\n",
      "57340 : 45872 5734 5734\n"
     ]
    }
   ],
   "source": [
    "train_posts, development_posts, test_posts = get_train_dev_test(\n",
    "    nps_chat.tagged_posts(tagset='universal'))\n",
    "\n",
    "train_sents, development_sents, test_sents = get_train_dev_test(\n",
    "    brown.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpSGy2VXyxDi"
   },
   "source": [
    "**Homework 8.1** (2 points, no programming needed)\n",
    "\n",
    "Please explain why POS taggers are important for natural language processing and what kinds of downstream tasks\n",
    "are enabled with POS tagging (give one example). What different strategies for implementing a POS tagger do you\n",
    "already know and what are the pros and cons of these approaches (name at least two). Do you have suggestions how\n",
    "they can be improved?\n",
    "\n",
    "Answer each question in two or three sentences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_tNVwBc_0rP"
   },
   "source": [
    "POS taggers are important because otherwise we wouldn't be able to distinguish what part of speech a token is. This would cause a lot of NLP tasks to be very difficult if not impossible. For example, machine translation (or anything where the meaning of text needs to be interpreted) would translate homographs the same way all of the time so that for example \"lead\" in  \"Lead is toxic\" and \"I lead the group\" would be translated to \"führe\" or \"Blei\" in both cases.\n",
    "\n",
    "Three different kinds of POS Taggers:\n",
    " - DefaultTagger: This kind of tagger simply assigns all tokens one and the same POS-tag. This is usually the most common tag.\n",
    "     - Pro: easy to implement, fast\n",
    "     - Con: Not very accurate and pretty much useless only approach\n",
    " - BigramTagger: This tagger takes the direct neighbors of a token into consideration when assigning the token a POS-tag.\n",
    "     - Pro: A lot more accurate, takes context into consideration\n",
    "     - Con: More training data needed for good results\n",
    "     \n",
    "A BigramTagger is a specific type of NgramTagger. By increasing N and taking more context into consideration, the results might improve. Otherwise, things like Deep Learning could help imporve the results of POS-tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tGGj8oPzAA9"
   },
   "source": [
    "**Homework 8.2** (8 points) \n",
    "\n",
    "Develop a part-of-speech tagger for texts in the chat domain and the brown corpus. You may explore several\n",
    "directions such as handling rare tokens, handling special chat related phenomena like smilies, or using better and\n",
    "more training data. You can try different things to improve the performance of the tagger on the training data, but be\n",
    "careful not to overfit on the training data. Document your ideas and process well. \n",
    "\n",
    "Hints:\n",
    "\n",
    "- You do not need to implement a tagger from scratch.\n",
    "- You may train your tagger on more than one corpus.\n",
    "- The corpora provided by NLTK offer a README in the corresponding folder, i.e. within the sub folders of ``nltk\n",
    "\\_data/corpora`` in your home folder (``Anwendungsdaten`` for Windows) you will find additional information.\n",
    "- Use the universal tag set.\n",
    "- Typical chat tokens like *’lol’* or *’:-)’* should be tagged as *’X’*, i.e. other.\n",
    "- Read the paragraph *“Tagging Unknown Words”*. (See NLTK-book page chapter 5.5, page 206)\n",
    "- use `import matplotlib.pyplot as plt` for the plotting\n",
    "\n",
    "\n",
    "Collect your top 3 results on the development set for the brown and the chat corpus with the diffrerent hyperparameters and plot them. \n",
    "Evaluate your best tagger for brown and the chat corpus on the testset. Upload the code and report the accuracy as part of your submission. Use the\n",
    "text field in the submission module to submit the final accuracy (just put a single number there for each corpus).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baselines Chat\n",
      "[0.1724051896207585, 0.8265968063872255, 0.5174650698602794, 0.4209081836327345]\n",
      "\n",
      "Baselines Brown\n",
      "[0.1853691247040087, 0.91269042978982, 0.454579744766455, 0.2907839316024392]\n"
     ]
    }
   ],
   "source": [
    "def calculate_baseline(corpora):\n",
    "    '''Calculates baseline values for the following taggers:\n",
    "        DefaultTagger, UnigramTagger, BigramTagger\n",
    "        \n",
    "        Attributes:\n",
    "            corpora: list of tuples (train_set, test_set)\n",
    "    '''\n",
    "    default_tagger = nltk.DefaultTagger('NOUN')\n",
    "    results = []\n",
    "    for corpus in corpora:\n",
    "        result = []\n",
    "        unigram_tagger = nltk.UnigramTagger(corpus[0])\n",
    "        bigram_tagger = nltk.BigramTagger(corpus[0])\n",
    "        trigram_tagger = nltk.NgramTagger(3, corpus[0])\n",
    "        \n",
    "        result.append(default_tagger.evaluate(corpus[1]))\n",
    "        result.append(unigram_tagger.evaluate(corpus[1]))\n",
    "        result.append(bigram_tagger.evaluate(corpus[1]))\n",
    "        result.append(trigram_tagger.evaluate(corpus[1]))\n",
    "        \n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "baselines = calculate_baseline([(train_posts, test_posts), (train_sents, test_sents)])\n",
    "\n",
    "print('Baselines Chat')\n",
    "print(baselines[0])\n",
    "print()\n",
    "print('Baselines Brown')\n",
    "print(baselines[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: Brown Corpus 1000\n",
      "0.8229919741832736\n",
      "0.8446491062634899\n",
      "0.8448586576140483\n",
      "Results: Brown Corpus 2000\n",
      "0.8521824773160663\n",
      "0.8694809413046667\n",
      "0.8694599861696108\n",
      "Results: Brown Corpus 3000\n",
      "0.8697952683305044\n",
      "0.8844114750319566\n",
      "0.8837723434127533\n",
      "Results: Brown Corpus 4000\n",
      "0.8810376982879655\n",
      "0.8939251063473104\n",
      "0.8933174074306909\n",
      "Results: Brown Corpus 5000\n",
      "0.8899960185243394\n",
      "0.9019090128035875\n",
      "0.9008193457806836\n",
      "Results: Chat Corpus 1000\n",
      "0.8265968063872255\n",
      "0.845309381237525\n",
      "0.843812375249501\n",
      "Results: Chat Corpus 2000\n",
      "0.8600299401197605\n",
      "0.875249500998004\n",
      "0.8727544910179641\n",
      "Results: Chat Corpus 3000\n",
      "0.8642714570858283\n",
      "0.8792415169660679\n",
      "0.876746506986028\n",
      "Results: Chat Corpus 4000\n",
      "0.8715069860279441\n",
      "0.8862275449101796\n",
      "0.8837325349301397\n",
      "Results: Chat Corpus 5000\n",
      "0.8779940119760479\n",
      "0.8924650698602794\n",
      "0.8904690618762475\n"
     ]
    }
   ],
   "source": [
    "def tag_unknown(corpus, n):\n",
    "    '''Executes the suggested approch from the nltk book 5.5\n",
    "        Attributes:\n",
    "            corpus: list of list of tagged tokens\n",
    "            n: number of most common tokens to be used\n",
    "        Returns:\n",
    "            list: list of list with tokens not included in n most common replaced\n",
    "    '''\n",
    "    most_common = [token for (token, _) in nltk.FreqDist([token for text in corpus for (token,_) in text]).most_common(n)]\n",
    "    new_sents = []\n",
    "    for text in corpus:\n",
    "        new_sent = []\n",
    "        for (token, tag) in text:\n",
    "            if token in most_common:\n",
    "                new_sent.append((token, tag))\n",
    "            else:\n",
    "                new_sent.append(('UNK', tag))\n",
    "        new_sents.append(new_sent)\n",
    "    return new_sents\n",
    "\n",
    "    \n",
    "def test_tagger(train_data, test_data, name):\n",
    "    default_tagger = nltk.DefaultTagger('NOUN')\n",
    "    unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
    "    bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
    "    trigram_tagger = nltk.NgramTagger(3, train_data, backoff=bigram_tagger)\n",
    "    \n",
    "    print('Results: ' + name)\n",
    "    print(unigram_tagger.evaluate(test_data))\n",
    "    print(bigram_tagger.evaluate(test_data))\n",
    "    print(trigram_tagger.evaluate(test_data))\n",
    "    \n",
    "test_tagger(tag_unknown(train_sents, 1000), tag_unknown(test_sents, 1000), 'Brown Corpus 1000')\n",
    "test_tagger(tag_unknown(train_sents, 2000), tag_unknown(test_sents, 2000), 'Brown Corpus 2000')\n",
    "test_tagger(tag_unknown(train_sents, 3000), tag_unknown(test_sents, 3000), 'Brown Corpus 3000')\n",
    "test_tagger(tag_unknown(train_sents, 4000), tag_unknown(test_sents, 4000), 'Brown Corpus 4000')\n",
    "test_tagger(tag_unknown(train_sents, 5000), tag_unknown(test_sents, 5000), 'Brown Corpus 5000')\n",
    "\n",
    "test_tagger(tag_unknown(train_posts, 1000), tag_unknown(test_posts, 1000), 'Chat Corpus 1000')\n",
    "test_tagger(tag_unknown(train_posts, 2000), tag_unknown(test_posts, 2000), 'Chat Corpus 2000')\n",
    "test_tagger(tag_unknown(train_posts, 3000), tag_unknown(test_posts, 3000), 'Chat Corpus 3000')\n",
    "test_tagger(tag_unknown(train_posts, 4000), tag_unknown(test_posts, 4000), 'Chat Corpus 4000')\n",
    "test_tagger(tag_unknown(train_posts, 5000), tag_unknown(test_posts, 5000), 'Chat Corpus 5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NOUN', 241528), ('VERB', 150459), ('ADP', 126332), ('.', 118482), ('DET', 116989), ('ADJ', 73866), ('ADV', 45940), ('PRON', 35550), ('CONJ', 32177), ('PRT', 23316), ('NUM', 13802), ('X', 1205)]\n",
      "[('NOUN', 7731), ('VERB', 7116), ('X', 5381), ('PRON', 3810), ('.', 3408), ('ADV', 1826), ('DET', 1778), ('ADP', 1635), ('ADJ', 1491), ('PRT', 784), ('CONJ', 567), ('NUM', 433)]\n",
      "Results: Brown Corpus 5000, VERB\n",
      "0.8601454286372876\n",
      "0.8706439513002662\n",
      "Results: Chat Corpus 5000, VERB\n",
      "0.842564870259481\n",
      "0.8577844311377245\n",
      "Results: Brown Corpus 5000, NUM\n",
      "0.8418411181660066\n",
      "0.853031160285828\n",
      "Results: Chat Corpus 5000, NUM\n",
      "0.8305888223552894\n",
      "0.842564870259481\n"
     ]
    }
   ],
   "source": [
    "freq_tags_brown = nltk.FreqDist([tag for text in train_sents for (_,tag) in text])\n",
    "print(freq_tags_brown.most_common(20))\n",
    "\n",
    "freq_tags_chat = nltk.FreqDist([tag for text in train_posts for (_,tag) in text])\n",
    "print(freq_tags_chat.most_common(20))\n",
    "\n",
    "def test_tagger_def(train_data, test_data, tag, name):\n",
    "    '''evalutes default, unigram, and bigram tagger\n",
    "        Attributes:\n",
    "            train_data: training data for tagger\n",
    "            test_data: test data for tagger\n",
    "            tag: tag to be used by DefaultTagger\n",
    "            name: name of corpus/test to be printed\n",
    "    '''\n",
    "    default_tagger = nltk.DefaultTagger(tag)\n",
    "    unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
    "    bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
    "    \n",
    "    print('Results: ' + name)\n",
    "    print(unigram_tagger.evaluate(test_data))\n",
    "    print(bigram_tagger.evaluate(test_data))\n",
    "\n",
    "test_tagger_def(tag_unknown(train_sents, 5000), tag_unknown(test_sents, 5000), 'VERB', 'Brown Corpus 5000, VERB')\n",
    "test_tagger_def(tag_unknown(train_posts, 5000), tag_unknown(test_posts, 5000), 'VERB', 'Chat Corpus 5000, VERB')\n",
    "test_tagger_def(tag_unknown(train_sents, 5000), tag_unknown(test_sents, 5000), 'NUM', 'Brown Corpus 5000, NUM')\n",
    "test_tagger_def(tag_unknown(train_posts, 5000), tag_unknown(test_posts, 5000), 'NUM', 'Chat Corpus 5000, NUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Brown: \n",
      "0.9380670983424488\n",
      "0.9462710337168123\n",
      "Results Chat: \n",
      "0.8602794411177644\n",
      "0.8832335329341318\n"
     ]
    }
   ],
   "source": [
    "# Test traing tagger using train_sents and train_posts\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NOUN')\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents+train_posts, backoff=default_tagger)\n",
    "bigram_tagger = nltk.BigramTagger(train_sents+train_posts, backoff=unigram_tagger)\n",
    "print('Results Brown: ')\n",
    "print(unigram_tagger.evaluate(test_sents))\n",
    "print(bigram_tagger.evaluate(test_sents))\n",
    "\n",
    "print('Results Chat: ')\n",
    "print(unigram_tagger.evaluate(test_posts))\n",
    "print(bigram_tagger.evaluate(test_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Brown: \n",
      "0.9398168521196119\n",
      "0.9485446658703716\n",
      "Results Chat: \n",
      "0.8807385229540918\n",
      "0.8962075848303394\n"
     ]
    }
   ],
   "source": [
    "# Using train_sents/train_posts + development_sents/development_posts\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NOUN')\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents+development_sents, backoff=default_tagger)\n",
    "bigram_tagger = nltk.BigramTagger(train_sents+development_sents, backoff=unigram_tagger)\n",
    "print('Results Brown: ')\n",
    "print(unigram_tagger.evaluate(test_sents))\n",
    "print(bigram_tagger.evaluate(test_sents))\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_posts+development_posts, backoff=default_tagger)\n",
    "bigram_tagger = nltk.BigramTagger(train_posts+development_posts, backoff=unigram_tagger)\n",
    "print('Results Chat: ')\n",
    "print(unigram_tagger.evaluate(test_posts))\n",
    "print(bigram_tagger.evaluate(test_posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: \n",
      "0.8807385229540918\n",
      "0.8962075848303394\n"
     ]
    }
   ],
   "source": [
    "def replace_tags(old_tag, new_tag, corpus):\n",
    "    '''replaces all of tags in a corpus\n",
    "        Attributes:\n",
    "            old_tag: tag to be replaced\n",
    "            new_tag: new tag to be used\n",
    "            corpus\n",
    "    '''\n",
    "    sents = []\n",
    "    for sentence in corpus:\n",
    "        sent = []\n",
    "        for (token,tag) in sentence:\n",
    "            if tag == old_tag:\n",
    "                tag == new_tag\n",
    "            sent.append((token, tag))\n",
    "        sents.append(sent)\n",
    "    return sents\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('NOUN')\n",
    "unigram_tagger = nltk.UnigramTagger(replace_tags('.', 'X', train_posts+development_posts), backoff=default_tagger)\n",
    "bigram_tagger = nltk.BigramTagger(replace_tags('.', 'X', train_posts+development_posts), backoff=unigram_tagger)\n",
    "print('Results: ')\n",
    "print(unigram_tagger.evaluate(test_posts))\n",
    "print(bigram_tagger.evaluate(test_posts))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes/Documentation\n",
    "\n",
    "### Baseline\n",
    "\n",
    "The first thing we did is check what kind of results we get without changing the data. For this, we chose to look a four common nltk taggers and see what our baseline values our so that. These were our results:\n",
    "\n",
    "#### Brown\n",
    "\n",
    "- **Default:** 0.185\n",
    "- **Unigram:** 0.912\n",
    "- **Bigram:** 0.454\n",
    "- **Trigram:** 0.290\n",
    "\n",
    "#### Chat\n",
    "\n",
    "- **Default:** 0.172\n",
    "- **Unigram:** 0.827\n",
    "- **Bigram:** 0.574\n",
    "- **Trigram:** 0.420\n",
    "\n",
    "In both corpora the UnigramTagger was the most successful. We found the accuracy of the basic UnigramTagger wuite surprising, as 0.912 and 0.827 are quite good accuracies.\n",
    "\n",
    "\n",
    "### NLTK 5.5 Tagging Unknown Words\n",
    "\n",
    "We then read the paragraph *Tagging Unknown Words* as suggested in the instructions and decided to implement a tagger like that. That means created a FreqDist of the most common words in each corpus and use only the most common *x* words and replace all others with the token \"UNK\". We experimented with different values of *x*. These were the results for each corpus with the different values of *x*.\n",
    "\n",
    "\n",
    "#### Brown\n",
    "\n",
    "##### 1000\n",
    "\n",
    "- **Unigram:** 0.823\n",
    "- **Bigram:** 0.845\n",
    "- **Trigram:** 0.845\n",
    "\n",
    "##### 2000\n",
    "\n",
    "- **Unigram:** 0.852\n",
    "- **Bigram:** 0.869\n",
    "- **Trigram:** 0.869\n",
    "\n",
    "##### 3000\n",
    "\n",
    "- **Unigram:** 0.869\n",
    "- **Bigram:** 0.884\n",
    "- **Trigram:** 0.884\n",
    "\n",
    "##### 4000\n",
    "\n",
    "- **Unigram:** 0.881\n",
    "- **Bigram:** 0.894\n",
    "- **Trigram:** 0.894\n",
    "\n",
    "##### 5000\n",
    "\n",
    "- **Unigram:** 0.890\n",
    "- **Bigram:** 0.902\n",
    "- **Trigram:** 0.901\n",
    "\n",
    "#### Chat\n",
    "\n",
    "##### 1000\n",
    "\n",
    "- **Unigram:** 0.827\n",
    "- **Bigram:** 0.845\n",
    "- **Trigram:** 0.844\n",
    "\n",
    "##### 2000\n",
    "\n",
    "- **Unigram:** 0.860\n",
    "- **Bigram:** 0.875\n",
    "- **Trigram:** 0.873\n",
    "\n",
    "##### 3000\n",
    "\n",
    "- **Unigram:** 0.864\n",
    "- **Bigram:** 0.879\n",
    "- **Trigram:** 0.877\n",
    "\n",
    "##### 4000\n",
    "\n",
    "- **Unigram:** 0.872\n",
    "- **Bigram:** 0.886\n",
    "- **Trigram:** 0.884\n",
    "\n",
    "##### 5000\n",
    "\n",
    "- **Unigram:** 0.878\n",
    "- **Bigram:** 0.892\n",
    "- **Trigram:** 0.890\n",
    "\n",
    "\n",
    "The best result was achieved with n=5000.\n",
    "\n",
    "Overall, the results were significantly better in all scenarios except for the UnigramTagger, which achieved a higher accuracy before. The best tagger seems to be the BigramTagger as it always outperforms the other two.\n",
    "\n",
    "The TrigramTagger was always the same or worse than the BigramTagger so we chose to not test the TrigramTagger any futher as it seems that the additional token context does not do anything to improve accuracy.\n",
    "\n",
    "\n",
    "### Changing DefaultTagger\n",
    "\n",
    "We decided to have the taggers fall back on each other, meaning the TrigramTagger falls back on the BigramTagger, which falls back on the UnigramTagger, which falls back on the DefaultTagger. The DefaultTagger tags everything as 'NOUN' and we decided to experiment with this to see if changing this would have an affect on our results. We decided to test this only on our best cases of the previous approach, meaning we tested with the replaced tokens with x=5000.\n",
    "\n",
    "We tested this with 'VERB' and 'NUM' and the results got considerably worse, which isn't really surprsing seeing as 'NOUN' is the most common tag in both corpora.\n",
    "\n",
    "### Training Data\n",
    "\n",
    "We decided to see what would happen if we used the same taggers for both corpora and used both sets of training data. We expected the results to get worse but wanted to see how much worse.\n",
    "\n",
    "As expected, the results got worse\n",
    "#### Results Brown: \n",
    "- UnigramTagger: 0.938\n",
    "- BigramTagger: 0.946\n",
    "\n",
    "#### Results Chat: \n",
    "- UnigramTagger: 0.860\n",
    "- BigramTagger: 0.883\n",
    "\n",
    "\n",
    "### Development Set\n",
    "\n",
    "We forgot about the development set until now. We decided to train the taggers using the respective development and training data and then test them again. Again we are using only the Unigram and BigramTagger and with all tokens not included in the most common 5000 replaced by 'UNK'.\n",
    "\n",
    "We expect the results to improve seeing as the taggers are trained on more relevant data. This happened as expected. The reason more training data here leads to better results whereas more data led to worse results in the previous approach (combining Brown and Chat training data) is most likely due to the fact that the Chat and Brown corpus are very different and cover different to\n",
    "\n",
    "#### Results Brown: \n",
    "\n",
    "- UnigramTagger: 0.940\n",
    "- BigramTagger: 0.949\n",
    "\n",
    "#### Results Chat: \n",
    "- UnigramTagger: 0.881\n",
    "- BigramTagger: 0.896\n",
    "\n",
    "### Changing Tags\n",
    "\n",
    "A last thought we had was changing all \".\" tags in the Chat corpus to \"X\" thinking that punctionation a lot of the time is part of typical chat tokens and therefore doing this might improve the results but this was not the case. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "FolT_Homework_8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
